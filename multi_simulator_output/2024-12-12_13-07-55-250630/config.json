{
    "seed": 42,
    "log_level": "info",
    "time_limit": 0,
    "cluster_config": {
        "num_replicas": [
            1
        ],
        "replica_config": {
            "model_names": [
                "meta-llama/Llama-2-7b-hf"
            ],
            "memory_margin_fraction": 0.1,
            "num_pipeline_stages": 1,
            "tensor_parallel_size": 1,
            "device": "a100",
            "network_device": "a100_pairwise_nvlink",
            "world_size": 1,
            "model_configs": [
                {
                    "num_layers": 32,
                    "num_q_heads": 32,
                    "num_kv_heads": 32,
                    "embedding_dim": 4096,
                    "mlp_hidden_dim": 11008,
                    "max_position_embeddings": 4096,
                    "use_gated_mlp": true,
                    "use_bias": false,
                    "use_qkv_bias": false,
                    "activation": 1,
                    "norm": 1,
                    "post_attn_norm": true,
                    "vocab_size": 32768,
                    "is_neox_style": true,
                    "rope_theta": 10000,
                    "rope_scaling": null,
                    "partial_rotary_factor": 1.0,
                    "no_tensor_parallel": false,
                    "name": "meta-llama/Llama-2-7b-hf"
                }
            ],
            "device_config": {
                "fp16_tflops": 312,
                "total_memory_gb": 80,
                "name": "a100"
            },
            "node_config": {
                "num_devices_per_node": 4,
                "device_sku_type": 2,
                "name": "a100_pairwise_nvlink"
            }
        },
        "global_scheduler_config": {
            "name": "round_robin"
        },
        "replica_scheduler_config": {
            "batch_size_cap": 128,
            "block_size": 16,
            "watermark_blocks_fraction": 0.01,
            "num_blocks": null,
            "chunk_size": 512,
            "name": "sarathi"
        }
    },
    "request_generator_config": {
        "seed": 42,
        "length_generator_config": {
            "seed": 42,
            "max_tokens": 4096,
            "prefill_tokens": 2048,
            "decode_tokens": 512,
            "name": "fixed"
        },
        "interval_generator_config": {
            "seed": 42,
            "qps": 0.5,
            "name": "poisson"
        },
        "num_requests": 128,
        "duration": null,
        "max_tokens": 4096,
        "name": "synthetic"
    },
    "execution_time_predictor_config": {
        "compute_input_file": "./data/profiling/compute/{DEVICE}/{MODEL}/mlp.csv",
        "attention_input_file": "./data/profiling/compute/{DEVICE}/{MODEL}/attention.csv",
        "all_reduce_input_file": "./data/profiling/network/{NETWORK_DEVICE}/all_reduce.csv",
        "send_recv_input_file": "./data/profiling/network/{NETWORK_DEVICE}/send_recv.csv",
        "cpu_overhead_input_file": "./data/profiling/cpu_overhead/{NETWORK_DEVICE}/{MODEL}/cpu_overheads.csv",
        "k_fold_cv_splits": 10,
        "no_cache": false,
        "kv_cache_prediction_granularity": 64,
        "prediction_max_prefill_chunk_size": 4096,
        "prediction_max_batch_size": 128,
        "prediction_max_tokens_per_request": 4096,
        "attention_decode_batching_overhead_fraction": 0.1,
        "attention_prefill_batching_overhead_fraction": 0.1,
        "nccl_cpu_launch_overhead_ms": 0.02,
        "nccl_cpu_skew_overhead_per_device_ms": 0.0,
        "num_training_job_threads": -1,
        "skip_cpu_overhead_modeling": true,
        "num_estimators": [
            250,
            500,
            750
        ],
        "max_depth": [
            8,
            16,
            32
        ],
        "min_samples_split": [
            2,
            5,
            10
        ],
        "name": "random_forrest"
    },
    "metrics_config": {
        "write_metrics": true,
        "write_json_trace": false,
        "wandb_project": null,
        "wandb_group": null,
        "wandb_run_name": null,
        "wandb_sweep_id": null,
        "wandb_run_id": null,
        "enable_chrome_trace": true,
        "save_table_to_wandb": false,
        "store_plots": true,
        "store_operation_metrics": false,
        "store_token_completion_metrics": false,
        "store_request_metrics": true,
        "store_batch_metrics": true,
        "store_utilization_metrics": true,
        "keep_individual_batch_metrics": false,
        "subsamples": null,
        "min_batch_index": null,
        "max_batch_index": null,
        "output_dir": "multi_simulator_output/2024-12-12_13-07-55-250630",
        "cache_dir": "cache"
    },
    "__flat_config__": {
        "seed": 42,
        "log_level": "info",
        "time_limit": 0,
        "cluster_config_num_replicas": [
            1
        ],
        "replica_config_model_names": [
            "meta-llama/Llama-2-7b-hf"
        ],
        "replica_config_memory_margin_fraction": 0.1,
        "replica_config_num_pipeline_stages": 1,
        "replica_config_tensor_parallel_size": 1,
        "replica_config_device": "a100",
        "replica_config_network_device": "a100_pairwise_nvlink",
        "global_scheduler_config_type": "round_robin",
        "replica_scheduler_config_type": "sarathi",
        "vllm_scheduler_config_batch_size_cap": 128,
        "vllm_scheduler_config_block_size": 16,
        "vllm_scheduler_config_watermark_blocks_fraction": 0.01,
        "vllm_scheduler_config_num_blocks": null,
        "vllm_scheduler_config_max_tokens_in_batch": 4096,
        "lightllm_scheduler_config_batch_size_cap": 128,
        "lightllm_scheduler_config_block_size": 16,
        "lightllm_scheduler_config_watermark_blocks_fraction": 0.01,
        "lightllm_scheduler_config_num_blocks": null,
        "lightllm_scheduler_config_max_tokens_in_batch": 4096,
        "lightllm_scheduler_config_max_waiting_iters": 10,
        "orca_scheduler_config_batch_size_cap": 128,
        "orca_scheduler_config_block_size": 16,
        "orca_scheduler_config_watermark_blocks_fraction": 0.01,
        "orca_scheduler_config_num_blocks": null,
        "faster_transformer_scheduler_config_batch_size_cap": 128,
        "faster_transformer_scheduler_config_block_size": 16,
        "faster_transformer_scheduler_config_watermark_blocks_fraction": 0.01,
        "faster_transformer_scheduler_config_num_blocks": null,
        "sarathi_scheduler_config_batch_size_cap": 128,
        "sarathi_scheduler_config_block_size": 16,
        "sarathi_scheduler_config_watermark_blocks_fraction": 0.01,
        "sarathi_scheduler_config_num_blocks": null,
        "sarathi_scheduler_config_chunk_size": 512,
        "request_generator_config_type": "synthetic",
        "synthetic_request_generator_config_seed": 42,
        "length_generator_config_type": "fixed",
        "trace_request_length_generator_config_seed": 42,
        "trace_request_length_generator_config_max_tokens": 4096,
        "trace_request_length_generator_config_trace_file": "data/processed_traces/sharegpt_8k_filtered_stats_llama2_tokenizer.csv",
        "trace_request_length_generator_config_prefill_scale_factor": 1,
        "trace_request_length_generator_config_decode_scale_factor": 1,
        "zipf_request_length_generator_config_seed": 42,
        "zipf_request_length_generator_config_max_tokens": 4096,
        "zipf_request_length_generator_config_theta": 0.6,
        "zipf_request_length_generator_config_scramble": false,
        "zipf_request_length_generator_config_min_tokens": 1024,
        "zipf_request_length_generator_config_prefill_to_decode_ratio": 20.0,
        "uniform_request_length_generator_config_seed": 42,
        "uniform_request_length_generator_config_max_tokens": 4096,
        "uniform_request_length_generator_config_min_tokens": 1024,
        "uniform_request_length_generator_config_prefill_to_decode_ratio": 20.0,
        "fixed_request_length_generator_config_seed": 42,
        "fixed_request_length_generator_config_max_tokens": 4096,
        "fixed_request_length_generator_config_prefill_tokens": 2048,
        "fixed_request_length_generator_config_decode_tokens": 512,
        "interval_generator_config_type": "poisson",
        "trace_request_interval_generator_config_seed": 42,
        "trace_request_interval_generator_config_trace_file": "data/processed_traces/AzureFunctionsInvocationTraceForTwoWeeksJan2021Processed.csv",
        "trace_request_interval_generator_config_start_time": "1970-01-04 12:00:00",
        "trace_request_interval_generator_config_end_time": "1970-01-04 15:00:00",
        "trace_request_interval_generator_config_time_scale_factor": 1.0,
        "poisson_request_interval_generator_config_seed": 42,
        "poisson_request_interval_generator_config_qps": 0.5,
        "gamma_request_interval_generator_config_seed": 42,
        "gamma_request_interval_generator_config_qps": 0.2,
        "gamma_request_interval_generator_config_cv": 0.5,
        "static_request_interval_generator_config_seed": 42,
        "synthetic_request_generator_config_num_requests": 128,
        "synthetic_request_generator_config_duration": null,
        "trace_request_generator_config_seed": 42,
        "trace_request_generator_config_trace_file": "data/processed_traces/splitwise_conv.csv",
        "trace_request_generator_config_prefill_scale_factor": 1.0,
        "trace_request_generator_config_decode_scale_factor": 1.0,
        "trace_request_generator_config_time_scale_factor": 1.0,
        "trace_request_generator_config_max_tokens": 4096,
        "execution_time_predictor_config_type": "random_forrest",
        "linear_regression_execution_time_predictor_config_compute_input_file": "./data/profiling/compute/{DEVICE}/{MODEL}/mlp.csv",
        "linear_regression_execution_time_predictor_config_attention_input_file": "./data/profiling/compute/{DEVICE}/{MODEL}/attention.csv",
        "linear_regression_execution_time_predictor_config_all_reduce_input_file": "./data/profiling/network/{NETWORK_DEVICE}/all_reduce.csv",
        "linear_regression_execution_time_predictor_config_send_recv_input_file": "./data/profiling/network/{NETWORK_DEVICE}/send_recv.csv",
        "linear_regression_execution_time_predictor_config_cpu_overhead_input_file": "./data/profiling/cpu_overhead/{NETWORK_DEVICE}/{MODEL}/cpu_overheads.csv",
        "linear_regression_execution_time_predictor_config_k_fold_cv_splits": 10,
        "linear_regression_execution_time_predictor_config_no_cache": false,
        "linear_regression_execution_time_predictor_config_kv_cache_prediction_granularity": 64,
        "linear_regression_execution_time_predictor_config_prediction_max_prefill_chunk_size": 4096,
        "linear_regression_execution_time_predictor_config_prediction_max_batch_size": 128,
        "linear_regression_execution_time_predictor_config_prediction_max_tokens_per_request": 4096,
        "linear_regression_execution_time_predictor_config_attention_decode_batching_overhead_fraction": 0.1,
        "linear_regression_execution_time_predictor_config_attention_prefill_batching_overhead_fraction": 0.1,
        "linear_regression_execution_time_predictor_config_nccl_cpu_launch_overhead_ms": 0.02,
        "linear_regression_execution_time_predictor_config_nccl_cpu_skew_overhead_per_device_ms": 0.0,
        "linear_regression_execution_time_predictor_config_num_training_job_threads": -1,
        "linear_regression_execution_time_predictor_config_skip_cpu_overhead_modeling": true,
        "linear_regression_execution_time_predictor_config_polynomial_degree": [
            1,
            2,
            3,
            4,
            5
        ],
        "linear_regression_execution_time_predictor_config_polynomial_include_bias": [
            true,
            false
        ],
        "linear_regression_execution_time_predictor_config_polynomial_interaction_only": [
            true,
            false
        ],
        "linear_regression_execution_time_predictor_config_fit_intercept": [
            true,
            false
        ],
        "random_forrest_execution_time_predictor_config_compute_input_file": "./data/profiling/compute/{DEVICE}/{MODEL}/mlp.csv",
        "random_forrest_execution_time_predictor_config_attention_input_file": "./data/profiling/compute/{DEVICE}/{MODEL}/attention.csv",
        "random_forrest_execution_time_predictor_config_all_reduce_input_file": "./data/profiling/network/{NETWORK_DEVICE}/all_reduce.csv",
        "random_forrest_execution_time_predictor_config_send_recv_input_file": "./data/profiling/network/{NETWORK_DEVICE}/send_recv.csv",
        "random_forrest_execution_time_predictor_config_cpu_overhead_input_file": "./data/profiling/cpu_overhead/{NETWORK_DEVICE}/{MODEL}/cpu_overheads.csv",
        "random_forrest_execution_time_predictor_config_k_fold_cv_splits": 10,
        "random_forrest_execution_time_predictor_config_no_cache": false,
        "random_forrest_execution_time_predictor_config_kv_cache_prediction_granularity": 64,
        "random_forrest_execution_time_predictor_config_prediction_max_prefill_chunk_size": 4096,
        "random_forrest_execution_time_predictor_config_prediction_max_batch_size": 128,
        "random_forrest_execution_time_predictor_config_prediction_max_tokens_per_request": 4096,
        "random_forrest_execution_time_predictor_config_attention_decode_batching_overhead_fraction": 0.1,
        "random_forrest_execution_time_predictor_config_attention_prefill_batching_overhead_fraction": 0.1,
        "random_forrest_execution_time_predictor_config_nccl_cpu_launch_overhead_ms": 0.02,
        "random_forrest_execution_time_predictor_config_nccl_cpu_skew_overhead_per_device_ms": 0.0,
        "random_forrest_execution_time_predictor_config_num_training_job_threads": -1,
        "random_forrest_execution_time_predictor_config_skip_cpu_overhead_modeling": true,
        "random_forrest_execution_time_predictor_config_num_estimators": [
            250,
            500,
            750
        ],
        "random_forrest_execution_time_predictor_config_max_depth": [
            8,
            16,
            32
        ],
        "random_forrest_execution_time_predictor_config_min_samples_split": [
            2,
            5,
            10
        ],
        "metrics_config_write_metrics": true,
        "metrics_config_write_json_trace": false,
        "metrics_config_wandb_project": null,
        "metrics_config_wandb_group": null,
        "metrics_config_wandb_run_name": null,
        "metrics_config_wandb_sweep_id": null,
        "metrics_config_wandb_run_id": null,
        "metrics_config_enable_chrome_trace": true,
        "metrics_config_save_table_to_wandb": false,
        "metrics_config_store_plots": true,
        "metrics_config_store_operation_metrics": false,
        "metrics_config_store_token_completion_metrics": false,
        "metrics_config_store_request_metrics": true,
        "metrics_config_store_batch_metrics": true,
        "metrics_config_store_utilization_metrics": true,
        "metrics_config_keep_individual_batch_metrics": false,
        "metrics_config_subsamples": null,
        "metrics_config_min_batch_index": null,
        "metrics_config_max_batch_index": null,
        "metrics_config_output_dir": "multi_simulator_output",
        "metrics_config_cache_dir": "cache"
    }
}